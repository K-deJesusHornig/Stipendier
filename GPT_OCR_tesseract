import openai
import fitz  # PyMuPDF
import pytesseract
from pytesseract import Output
from PIL import Image
import io

# Set your OpenAI API key
openai.api_key = 'your-api-key'

# Function to extract images from PDF
def extract_images_from_pdf(pdf_path):
    pdf_document = fitz.open(pdf_path)
    images = []
    for page_num in range(len(pdf_document)):
        page = pdf_document.load_page(page_num)
        for img in page.get_images(full=True):
            xref = img[0]
            base_image = pdf_document.extract_image(xref)
            image_bytes = base_image["image"]
            image = Image.open(io.BytesIO(image_bytes))
            images.append(image)
    return images

# Function to apply OCR to images and extract Swedish text
def apply_ocr_to_images(images):
    ocr_results = []
    for image in images:
        text = pytesseract.image_to_string(image, lang='swe', output_type=Output.STRING)
        ocr_results.append(text)
    return ocr_results

# Function to transcribe text using OpenAI API
def transcribe_texts(ocr_texts):
    transcriptions = []
    for text in ocr_texts:
        response = openai.Completion.create(
            engine="text-davinci-003",
            prompt=text,
            max_tokens=2048,
            n=1,
            stop=None,
            temperature=0.7
        )
        transcriptions.append(response.choices[0].text.strip())
    return transcriptions

# Main function
def main(pdf_path):
    images = extract_images_from_pdf(pdf_path)
    ocr_texts = apply_ocr_to_images(images)
    transcriptions = transcribe_texts(ocr_texts)
    for idx, transcription in enumerate(transcriptions):
        print(f"Transcription for image {idx + 1}:\n{transcription}\n")

if __name__ == "__main__":
    pdf_path = 'path-to-your-pdf-file.pdf'
    main(pdf_path)